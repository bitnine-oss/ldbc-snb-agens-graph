\timing on

-- Set the source path
\set source_path '/absolute/path/to/social_network'

drop graph ldbc cascade;
create graph ldbc;
set graph_path = ldbc;

-- Make Vertex Labels
create vlabel Forum;
create vlabel Message;
create vlabel Post inherits (Message);
create vlabel "Comment" inherits (Message);
create vlabel Organization;
create vlabel Person;
create vlabel Place;
create vlabel Tag;
create vlabel TagClass;

-- Make Edge Labels
create elabel hasMember;
create elabel hasTagPost;
create elabel hasTagComment;
create elabel hasTagForum;
create elabel hasInterest;
create elabel knows;
create elabel likes;
create elabel likesPost inherits (likes);
create elabel likesComment inherits (likes);
create elabel studyAt;
create elabel workAt;
create elabel hasType;
create elabel isSubclassOf;
create elabel replyOf;

-- Make Unlogged
alter vlabel Forum set unlogged;
alter vlabel Message set unlogged;
alter vlabel Post set unlogged;
alter vlabel "Comment" set unlogged;
alter vlabel Organization set unlogged;
alter vlabel Person set unlogged;
alter vlabel Place set unlogged;
alter vlabel Tag set unlogged;
alter vlabel TagClass set unlogged;
alter elabel hasMember set unlogged;
alter elabel hasTagPost set unlogged;
alter elabel hasTagComment set unlogged;
alter elabel hasTagForum set unlogged;
alter elabel hasInterest set unlogged;
alter elabel knows set unlogged;
alter elabel likes set unlogged;
alter elabel likesPost set unlogged;
alter elabel likesComment set unlogged;
alter elabel studyAt set unlogged;
alter elabel workAt set unlogged;
alter elabel hasType set unlogged;
alter elabel isSubclassOf set unlogged;
alter elabel replyOf set unlogged;

-- Drop Indexes
drop constraint Forum_pkey on Forum;
drop constraint Message_pkey on Message;
drop constraint Post_pkey on Post;
drop constraint "Comment_pkey" on "Comment";
drop constraint Organization_pkey on Organization;
drop constraint Person_pkey on Person;
drop constraint Place_pkey on Place;
drop constraint Tag_pkey on Tag;
drop constraint TagClass_pkey on TagClass;

drop index ldbc.forum_properties_idx;
drop index ldbc.message_properties_idx;
drop index ldbc.post_properties_idx;
drop index ldbc."Comment_properties_idx";
drop index ldbc.organization_properties_idx;
drop index ldbc.person_properties_idx;
drop index ldbc.place_properties_idx;
drop index ldbc.tag_properties_idx;
drop index ldbc.tagclass_properties_idx;

drop index ldbc.hasMember_start_idx;
drop index ldbc.hasTagPost_start_idx;
drop index ldbc.hasTagComment_start_idx;
drop index ldbc.hasTagForum_start_idx;
drop index ldbc.hasInterest_start_idx;
drop index ldbc.knows_start_idx;
drop index ldbc.likes_start_idx;
drop index ldbc.likesPost_start_idx;
drop index ldbc.likesComment_start_idx;
drop index ldbc.studyAt_start_idx;
drop index ldbc.workAt_start_idx;
drop index ldbc.hasType_start_idx;
drop index ldbc.isSubclassOf_start_idx;
drop index ldbc.replyOf_start_idx;

drop index ldbc.hasMember_end_idx;
drop index ldbc.hasTagPost_end_idx;
drop index ldbc.hasTagComment_end_idx;
drop index ldbc.hasTagForum_end_idx;
drop index ldbc.hasInterest_end_idx;
drop index ldbc.knows_end_idx;
drop index ldbc.likes_end_idx;
drop index ldbc.likesPost_end_idx;
drop index ldbc.likesComment_end_idx;
drop index ldbc.studyAt_end_idx;
drop index ldbc.workAt_end_idx;
drop index ldbc.hasType_end_idx;
drop index ldbc.isSubclassOf_end_idx;
drop index ldbc.replyOf_end_idx;

drop index ldbc.hasMember_id_idx;
drop index ldbc.hasTagPost_id_idx;
drop index ldbc.hasTagComment_id_idx;
drop index ldbc.hasTagForum_id_idx;
drop index ldbc.hasInterest_id_idx;
drop index ldbc.knows_id_idx;
drop index ldbc.likes_id_idx;
drop index ldbc.likesPost_id_idx;
drop index ldbc.likesComment_id_idx;
drop index ldbc.studyAt_id_idx;
drop index ldbc.workAt_id_idx;
drop index ldbc.hasType_id_idx;
drop index ldbc.isSubclassOf_id_idx;
drop index ldbc.replyOf_id_idx;

drop index ldbc.hasMember_properties_idx;
drop index ldbc.hasTagPost_properties_idx;
drop index ldbc.hasTagComment_properties_idx;
drop index ldbc.hasTagForum_properties_idx;
drop index ldbc.hasInterest_properties_idx;
drop index ldbc.knows_properties_idx;
drop index ldbc.likes_properties_idx;
drop index ldbc.likesPost_properties_idx;
drop index ldbc.likesComment_properties_idx;
drop index ldbc.studyAt_properties_idx;
drop index ldbc.workAt_properties_idx;
drop index ldbc.hasType_properties_idx;
drop index ldbc.isSubclassOf_properties_idx;
drop index ldbc.replyOf_properties_idx;

-----------------------------------------------------------------------------------------------
-- Loading vertexes from FDW
-- In this stage, ID references (e.g. creator in Post) are converted to GID references.
-- GID refereces are added as additional properties whose prefix is 'gid_'.
-- Previous ID references are also preserved. These are also used like for weight calculation.
-----------------------------------------------------------------------------------------------

-- Place
\set file_name :source_path/place_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwPlace;
create foreign table fdwPlace
(
	id int8,
	name varchar(200),
	url varchar(200),
	type varchar(80),
	isPartOf int8
)
server graph_import
options
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);

LOAD FROM fdwPlace AS row
CREATE (:Place =JSONB_STRIP_NULLS(ROW_TO_JSON(row)::JSONB));

MATCH (pl1:place), (pl2: place)
WHERE pl1.ispartof = pl2.id
SET pl1.gid_ispartof = to_json(id(pl2));

CREATE UNIQUE INDEX ON ldbc.place (((properties #>> '{id}'::text[])::int8));
VACUUM ANALYZE ldbc.place;

-- Person
DROP VIEW person_view;

\set file_name :source_path/person_0_0.csv
\echo Start Loading :file_name

DROP FOREIGN TABLE fdwPerson;
CREATE FOREIGN TABLE fdwPerson
(
	id INT8,
	firstName VARCHAR(80),
	lastName VARCHAR(80),
	gender VARCHAR(6),
	birthday INT8,
	creationDate INT8,
	locationIP VARCHAR(80),
	browserUsed VARCHAR(80),
	place INT8
)
SERVER graph_import
OPTIONS
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);

-- Person's email
\set file_name :source_path/person_email_emailaddress_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwEmail;
create foreign table fdwEmail
(
	id int8,
	email varchar(200)
)
server graph_import
options
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);

-- Person's language
\set file_name :source_path/person_speaks_language_0_0.csv
\echo Start Loading :file_name

DROP FOREIGN TABLE fdwLanguage;
CREATE FOREIGN TABLE fdwLanguage
(
	id INT8,
	language VARCHAR(200)
)
SERVER graph_import
OPTIONS
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);

CREATE VIEW person_view AS (
    SELECT p.*, email, speaks
    FROM
        fdwPerson p LEFT OUTER JOIN
		(SELECT id, ARRAY_AGG(email) email FROM fdwEmail GROUP BY id) e ON p.id = e.id LEFT OUTER JOIN
		(SELECT id, ARRAY_AGG(language) speaks FROM fdwLanguage GROUP BY id) l ON p.id = l.id
);

LOAD FROM person_view AS row
MATCH (pl:place) WHERE pl.id = (row).place
CREATE (:Person = JSONB_SET(JSONB_STRIP_NULLS(ROW_TO_JSON(row)::JSONB), '{gid_place}', TO_JSONB(id(pl))));

CREATE UNIQUE INDEX ON ldbc.person (((properties).id::int8));
VACUUM ANALYZE ldbc.person;

-- Forum
\set file_name :source_path/forum_0_0.csv
\echo Start Loading :file_name

DROP FOREIGN TABLE fdwForum;
CREATE FOREIGN TABLE fdwForum
(
	id INT8,
	title VARCHAR(256),
	creationDate INT8,
	moderator INT8
)
SERVER graph_import
OPTIONS
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);

LOAD FROM fdwForum AS row
MATCH (p:person)
WHERE p.id::int8 = (row).moderator
CREATE (:Forum = JSONB_SET(JSONB_STRIP_NULLS(ROW_TO_JSON(row)::jsonb), '{gid_moderator}', TO_JSONB(id(p))));

CREATE UNIQUE INDEX ON ldbc.forum (((properties).id::int8));
VACUUM analyze ldbc.forum;

-- Message
--- Post (inherits Message)
\set file_name :source_path/post_0_0.csv
\echo Start Loading :file_name

DROP VIEW PostBase;
DROP FOREIGN TABLE fdwPost;
CREATE FOREIGN TABLE fdwPost
(
	id INT8,
    imageFile VARCHAR(80),
	creationDate INT8,
	locationIP VARCHAR(80),
	browserUsed VARCHAR(80),
	language VARCHAR(80),
	content TEXT,
	length INT4,
	creator INT8,
	forumID INT8,
	place INT8
)
SERVER graph_import
OPTIONS
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);
CREATE VIEW PostBase AS
 	SELECT id, creationDate, imageFile, content, creator, forumID, place
	FROM fdwPost;

LOAD FROM PostBase AS row
MATCH (p:person), (f:forum), (pl:place)
WHERE p.id::INT8 = (row).creator AND f.id::INT8 = (row).forumid AND pl.id::INT8 = (row).place
CREATE (:post =
		JSONB_SET(
		  JSONB_SET(JSONB_SET(JSONB_STRIP_NULLS(ROW_TO_JSON(row)::JSONB), 
			'{gid_creator}', TO_JSONB(ID(p))), '{gid_forumid}', TO_JSONB(ID(f))), '{gid_place}', TO_JSONB(ID(pl))));

DROP TABLE msgext;
CREATE TABLE msgext AS
	SELECT id, locationIP, browserUsed, language, length, content, imagefile
	FROM fdwPost;

--- Comment (inherits Message)
\set file_name :source_path/comment_0_0.csv
\echo Start Loading :file_name

drop view CommentBase;
drop foreign table fdwComment;
create foreign table fdwComment
	(
		id int8,
		creationDate int8,
		locationIP varchar(80),
		browserUsed varchar(80),
		content varchar(2000),
		length int4,
		creator int8,
		place int8,
		replyOfPost int8,
		replyOfComment int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
create view CommentBase AS
 	select id, creationDate, content, creator, place, replyofpost, replyOfComment
	from fdwComment;

LOAD FROM CommentBase as row
MATCH (p:person), (pl:place)
WHERE p.id::int8 = (row).creator AND pl.id::int8 = (row).place
CREATE (:"Comment" =
		  jsonb_set(jsonb_set(jsonb_strip_nulls(row_to_json(row)::jsonb), 
			'{gid_creator}', to_jsonb(id(p))), '{gid_place}', to_jsonb(id(pl))));

insert into msgext
	select id, locationIP, browserUsed, null, length, content, null
	from fdwComment;

create unique index msgext_idx on msgext (id);

-- Organization
\set file_name :source_path/organisation_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwOrganization;
create foreign table fdwOrganization
(
	id int8,
	type varchar(80),
	name varchar(200),
	url varchar(200),
	place int8
)
server graph_import
options
(
	 FORMAT 'csv',
	 HEADER 'true',
	 DELIMITER '|',
	 NULL '',
	 FILENAME :'file_name'
);

LOAD FROM fdwOrganization AS row
MATCH (pl:place)
WHERE pl.id::int8 = (row).place
CREATE (:Organization = 
		  jsonb_set(jsonb_strip_nulls(row_to_json(row)::jsonb),
				    '{gid_place}', to_jsonb(id(pl))));

-- Tag
\set file_name :source_path/tag_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwTag;
create foreign table fdwTag
	(
		id int8,
		name varchar(200),
		url varchar(200)
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwTag as row
create (:Tag =jsonb_strip_nulls(row_to_json(row)::jsonb));

-- TagClass
\set file_name :source_path/tagclass_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwTagClass;
create foreign table fdwTagClass
	(
		id int8,
		name varchar(200),
		url varchar(200)
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwTagClass as row
create (:TagClass =jsonb_strip_nulls(row_to_json(row)::jsonb));

-- Make property indexes for 'id' field of vertexes
--- should be replaced to using CREATE PROPERTY INDEX
---- property
--create PROPERTY index on forum (id);
--create PROPERTY index on message (id);
--create PROPERTY index on post (id);
--create PROPERTY index on "Comment" (id);
--create PROPERTY index on organization (id);
--create PROPERTY index on person (id);
--create PROPERTY index on place (id);
--create PROPERTY index on tag (id);
--create PROPERTY index on tagclass (id);
create UNIQUE index on ldbc.message (((properties #>> '{id}'::text[])::int8));
create UNIQUE index on ldbc.post (((properties #>> '{id}'::text[])::int8));
create UNIQUE index on ldbc."Comment" (((properties #>> '{id}'::text[])::int8));
create UNIQUE index on ldbc.organization (((properties #>> '{id}'::text[])::int8));
create UNIQUE index on ldbc.person (((properties #>> '{id}'::text[])::int8));
create UNIQUE index on ldbc.tag (((properties #>> '{id}'::text[])::int8));
create UNIQUE index on ldbc.tagclass (((properties #>> '{id}'::text[])::int8));

-- Analyze vertices
VACUUM analyze ldbc.message;
VACUUM analyze ldbc.post;
VACUUM analyze ldbc."Comment";
VACUUM analyze ldbc.organization;
VACUUM analyze ldbc.tag;
VACUUM analyze ldbc.tagclass;

-- Edge

-- hasMember
\set file_name :source_path/forum_hasMember_person_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwHasMember;
create foreign table fdwHasMember
	(
		forumId int8,
		personId int8,
		joinDate int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwHasMember as row
match (r:Forum), (s:Person)
where (r).id::int8 = (row).forumId and (s).id::int8 = (row).personId
create (r)-[:hasMember {'joinDate': (row).joinDate}]->(s);

--- hasTag (post)
\set file_name :source_path/post_hasTag_tag_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwPostHasTag;
create foreign table fdwPostHasTag
	(
		postId int8,
		tagId int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwPostHasTag as row
match (r:Post), (s:Tag)
where (r).id::int8 = (row).postId and (s).id::int8 = (row).tagId
create (r)-[:hasTagPost]->(s);

--- hasTag (comment)
\set file_name :source_path/comment_hasTag_tag_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwCommentHasTag;
create foreign table fdwCommentHasTag
	(
		commentId int8,
		tagId int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwCommentHasTag as row
match (r:"Comment"), (s:Tag)
where (r).id::int8 = (row).commentId and (s).id::int8 = (row).tagId
create (r)-[:hasTagComment]->(s);

--- hasTag (forum)
\set file_name :source_path/forum_hasTag_tag_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwForumHasTag;
create foreign table fdwForumHasTag
	(
		forumId int8,
		tagId int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwForumHasTag as row
match (r:Forum), (s:Tag)
where (r).id::int8 = (row).forumId and (s).id::int8 = (row).tagId
create (r)-[:hasTagForum]->(s);

--- hasInterest
\set file_name :source_path/person_hasInterest_tag_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwHasInterest;
create foreign table fdwHasInterest
	(
		personId int8,
		tagId int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwHasInterest as row
match (r:Person), (s:Tag)
where (r).id::int8 = (row).personId and (s).id::int8 = (row).tagId
create (r)-[:hasInterest]->(s);

--- knows
\set file_name :source_path/person_knows_person_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwKnows;
create foreign table fdwKnows
	(
		person1Id int8,
		person2Id int8,
		creationDate int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwKnows as row
match (r:Person), (s:Person)
where (r).id::int8 = (row).person1Id and (s).id::int8 = (row).person2Id
create (r)-[:knows {'creationDate': (row).creationDate}]->(s)
create (s)-[:knows {'creationDate': (row).creationDate}]->(r);

--- likes (post)
\set file_name :source_path/person_likes_post_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwLikesPost;
create foreign table fdwLikesPost
	(
		personId int8,
		postId int8,
		creationDate int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwLikesPost as row
match (r:Person), (s:Post)
where (r).id::int8 = (row).personId and (s).id::int8 = (row).postId
create (r)-[:likesPost {'creationDate': (row).creationDate}]->(s);

--- likes (comment)
\set file_name :source_path/person_likes_comment_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwLikesComment;
create foreign table fdwLikesComment
	(
		personId int8,
		commentId int8,
		creationDate int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwLikesComment as row
match (r:Person), (s:"Comment")
where (r).id::int8 = (row).personId and (s).id::int8 = (row).commentId
create (r)-[:likesComment {'creationDate': (row).creationDate}]->(s);

--- studyAt
\set file_name :source_path/person_studyAt_organisation_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwStudyAt;
create foreign table fdwStudyAt
	(
		personId int8,
		organId int8,
		classYear char(4)
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwStudyAt as row
match (r:Person), (s:Organization)
where (r).id::int8 = (row).personId and (s).id::int8 = (row).organId
create (r)-[:studyAt {'classYear': (row).classYear}]->(s);

--- workAt
\set file_name :source_path/person_workAt_organisation_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwWorkAt;
create foreign table fdwWorkAt
	(
		personId int8,
		organId int8,
		workFrom char(4)
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwWorkAt as row
match (r:Person), (s:Organization)
where (r).id::int8 = (row).personId and (s).id::int8 = (row).organId
create (r)-[:workAt {'workFrom': (row).workFrom}]->(s);

--- hasType
\set file_name :source_path/tag_hasType_tagclass_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwHasType;
create foreign table fdwHasType
	(
		tagId int8,
		tagclassId int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwHasType as row
match (r:Tag), (s:TagClass)
where (r).id::int8 = (row).tagId and (s).id::int8 = (row).tagclassId
create (r)-[:hasType]->(s);

--- isSubclassOf
\set file_name :source_path/tagclass_isSubclassOf_tagclass_0_0.csv
\echo Start Loading :file_name

drop foreign table fdwIsSubclassOf;
create foreign table fdwIsSubclassOf
	(
		tagclass1Id int8,
		tagclass2Id int8
	)
	server graph_import
	options
	(
		 FORMAT 'csv',
		 HEADER 'true',
		 DELIMITER '|',
		 NULL '',
		 FILENAME :'file_name'
	);
load from fdwIsSubclassOf as row
match (r:TagClass), (s:TagClass)
where (r).id::int8 = (row).tagclass1Id and (s).id::int8 = (row).tagclass2Id
create (r)-[:isSubclassOf]->(s);

--- replyOf
MATCH (c:"Comment"), (m:message)
WHERE (c.replyofpost::int8 = m.id::int8 or c.replyofcomment::int8 = m.id::int8)
CREATE (c)-[:replyof]->(m);

-- create index

-- vertices
create unique index on ldbc.Forum (id);
create unique index on ldbc.Message (id);
create unique index on ldbc.Post (id);
create unique index on ldbc."Comment" (id);
create unique index on ldbc.Organization (id);
create unique index on ldbc.Person (id);
create unique index on ldbc.Place (id);
create unique index on ldbc.Tag (id);
create unique index on ldbc.TagClass (id);

-- gin
create index on ldbc.forum using gin(properties jsonb_path_ops);
create index on ldbc.post using gin(properties jsonb_path_ops);
create index on ldbc.message using gin(properties jsonb_path_ops);
create index on ldbc."Comment" using gin(properties jsonb_path_ops);
create index on ldbc.organization using gin(properties jsonb_path_ops);
create index on ldbc.person using gin(properties jsonb_path_ops);
create index on ldbc.place using gin(properties jsonb_path_ops);
create index on ldbc.tag using gin(properties jsonb_path_ops);
create index on ldbc.tagclass using gin(properties jsonb_path_ops);

-- edges
create index on ldbc.hasMember (id);
create index on ldbc.hasTagPost (id);
create index on ldbc.hasTagComment (id);
create index on ldbc.hasTagForum (id);
create index on ldbc.hasInterest (id);
create index on ldbc.knows (id);
create index on ldbc.likes (id);
create index on ldbc.likesPost (id);
create index on ldbc.likesComment (id);
create index on ldbc.studyAt (id);
create index on ldbc.workAt (id);
create index on ldbc.hasType (id);
create index on ldbc.isSubclassOf (id);
create index on ldbc.replyOf (id);

create index on ldbc.hasMember (start, "end", id);
create index on ldbc.hasTagPost (start, "end", id);
create index on ldbc.hasTagComment (start, "end", id);
create index on ldbc.hasTagForum (start, "end", id);
create index on ldbc.hasInterest (start, "end", id);
create index on ldbc.knows (start, "end", id);
create index on ldbc.likes (start, "end", id);
create index on ldbc.likesPost (start, "end", id);
create index on ldbc.likesComment (start, "end", id);
create index on ldbc.studyAt (start, "end", id);
create index on ldbc.workAt (start, "end", id);
create index on ldbc.hasType (start, "end", id);
create index on ldbc.isSubclassOf (start, "end", id);
create index on ldbc.replyOf (start, "end", id);

create index on ldbc.hasMember ("end", start, id);
create index on ldbc.hasTagPost ("end", start, id);
create index on ldbc.hasTagComment ("end", start, id);
create index on ldbc.hasTagForum ("end", start, id);
create index on ldbc.hasInterest ("end", start, id);
create index on ldbc.knows ("end", start, id);
create index on ldbc.likes ("end", start, id);
create index on ldbc.likesPost ("end", start, id);
create index on ldbc.likesComment ("end", start, id);
create index on ldbc.studyAt ("end", start, id);
create index on ldbc.workAt ("end", start, id);
create index on ldbc.hasType ("end", start, id);
create index on ldbc.isSubclassOf ("end", start, id);
create index on ldbc.replyOf ("end", start, id);

-- gin
create index on ldbc.hasMember using gin(properties jsonb_path_ops);
create index on ldbc.hasTagPost using gin(properties jsonb_path_ops);
create index on ldbc.hasTagComment using gin(properties jsonb_path_ops);
create index on ldbc.hasTagForum using gin(properties jsonb_path_ops);
create index on ldbc.hasInterest using gin(properties jsonb_path_ops);
create index on ldbc.knows using gin(properties jsonb_path_ops);
create index on ldbc.likes using gin(properties jsonb_path_ops);
create index on ldbc.likesPost using gin(properties jsonb_path_ops);
create index on ldbc.likesComment using gin(properties jsonb_path_ops);
create index on ldbc.studyat using gin(properties jsonb_path_ops);
create index on ldbc.workat using gin(properties jsonb_path_ops);
create index on ldbc.hasType using gin(properties jsonb_path_ops);
create index on ldbc.isSubclassOf using gin(properties jsonb_path_ops);
create index on ldbc.replyOf using gin(properties jsonb_path_ops);

-- Addtional indexes and Cluster
create property index message_cc_idx
	on message (("gid_creator"::graphid), ("creationdate"::int8));
create property index post_cc_idx
	on post (("gid_creator"::graphid),("creationdate"::int8));
create property index comment_cc_idx
	on "Comment" (("gid_creator"::graphid),("creationdate"::int8));

cluster verbose ldbc.message using message_cc_idx;
cluster verbose ldbc.post using post_cc_idx;
cluster verbose ldbc."Comment" using comment_cc_idx;

create property index post_fc_idx
	on post (("gid_forumid"::graphid),("gid_creator"::graphid));

create property index comment_replyofpost_idx
	on "Comment" (("replyofpost"::int8));
create property index comment_replyofcomment_idx
	on "Comment" (("replyofcomment"::int8));

create unique index on ldbc.hasMember (
	"end", ((properties #>> '{joinDate}'::text[])::int8), start, id);

--create index on ldbc.person (((properties #>> '{place}'::text[])::int8));
--
--create index on ldbc.place (((properties #>> '{ispartof}'::text[])::int8));
--
--create unique index on ldbc.likes (
--	start , ((properties #>> '{creationDate}'::text[])::int8), "end", id);
--create unique index on ldbc.likesPost (
--	start , ((properties #>> '{creationDate}'::text[])::int8), "end", id);
--create unique index on ldbc.likesComment (
--	start , ((properties #>> '{creationDate}'::text[])::int8), "end", id);
--
--create index on ldbc.hasTagPost ("end");
--create index on ldbc.hasTagComment ("end");

-- pre_eval weights
DROP TABLE c14_weight;
CREATE UNLOGGED TABLE c14_weight(p1 int8, p2 int8, weight double precision);
INSERT INTO c14_weight
    SELECT p1, p2, SUM(inc) FROM (
        SELECT
            CASE when rep_creator < org_creator
                THEN rep_creator ELSE org_creator END AS p1,
            CASE when rep_creator < org_creator
                THEN org_creator ELSE rep_creator END AS p2,
            inc
        FROM (
            MATCH (p1:person)-[:knows]->(p2:person),
			      (c:"Comment")-[:replyof]->(m:Post)
		    WHERE id(p1) = c.gid_creator::graphid AND id(p2) = m.gid_creator::graphid
            RETURN p1.id::int8 AS rep_creator, p2.id::int8 AS org_creator, 1.0 AS inc
            UNION ALL
            MATCH (p1:person)-[:knows]->(p2:person),
			      (c:"Comment")-[:replyof]->(m:"Comment")
		    WHERE id(p1) = c.gid_creator::graphid AND id(p2) = m.gid_creator::graphid
            RETURN p1.id::int8 AS rep_creator, p2.id::int8 AS org_creator, 0.5 AS inc
		) _
	) p
    GROUP BY p1, p2;
CREATE UNIQUE INDEX ON c14_weight(p1, p2);
ALTER TABLE c14_weight SET LOGGED;

-- Analyze vertices
VACUUM analyze ldbc.forum;
VACUUM analyze ldbc.message;
VACUUM analyze ldbc.post;
VACUUM analyze ldbc."Comment";
VACUUM analyze ldbc.organization;
VACUUM analyze ldbc.person;
VACUUM analyze ldbc.place;
VACUUM analyze ldbc.tag;
VACUUM analyze ldbc.tagclass;

-- Analyze edges
VACUUM analyze ldbc.hasMember;
VACUUM analyze ldbc.hasTagPost;
VACUUM analyze ldbc.hasTagComment;
VACUUM analyze ldbc.hasTagForum;
VACUUM analyze ldbc.hasInterest;
VACUUM analyze ldbc.knows;
VACUUM analyze ldbc.likes;
VACUUM analyze ldbc.likesPost;
VACUUM analyze ldbc.likesComment;
VACUUM analyze ldbc.studyAt;
VACUUM analyze ldbc.workAt;
VACUUM analyze ldbc.hasType;
VACUUM analyze ldbc.isSubclassOf;
